{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "â“’ 2022 CCNets Inc."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://ccnets.org"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install scikit-learn==1.1 --user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sklearn\n",
        "sklearn.__version__"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "path_append = \"../\"\n",
        "sys.path.append(path_append)  # Go up one directory from where you are.\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataroot = path_append + \"../data/creditcardfraud/creditcard.csv\"\n",
        "df = pd.read_csv(dataroot)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('No Frauds', round(df['Class'].value_counts()[0] / len(df) *100,2), '%of the dataset')\n",
        "print('Frauds', round(df['Class'].value_counts()[1] / len(df) *100,2), '%of the dataset')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DataLoader"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_7_DeepLearning/FeedForwardNeuralNetworks.html\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        vals = torch.tensor(self.x[index], dtype = torch.float32)\n",
        "        label = torch.tensor(self.y[index], dtype= torch.float32).unsqueeze(-1)\n",
        "        return vals, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df[['Class']]\n",
        "X = df.drop(['Class'],axis=1)\n",
        "\n",
        "sc = RobustScaler()\n",
        "X['scaled_amount'] = sc.fit_transform(X['Amount'].values.reshape(-1,1))\n",
        "X['scaled_time'] = sc.fit_transform(X['Time'].values.reshape(-1,1))\n",
        "X.drop(['Time','Amount'], axis=1, inplace=True)\n",
        "X = X[:]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ccnets.config import get_parser\n",
        "from ccnets.ccnets import CCNets\n",
        "from ccnets.resnets import ResNets\n",
        "from nn.custom_deepfm import DeepFM\n",
        "from nn.custom_dnn import ResMLP, MLP \n",
        "from ccnets.utils.log import create_log_details, create_log_name\n",
        "from ccnets.utils.setting import set_random_seed\n",
        "\n",
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "args = get_parser()\n",
        "args.device = torch.device('cuda:0' if (torch.cuda.is_available() and args.ngpu > 0) else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import IPython ; file_path = IPython.extract_module_locals()[1]['__vsc_ipynb_file__']\n",
        "from pathlib import Path\n",
        "file_name = Path(file_path).stem\n",
        "model_path = path_append + f\"models/{file_name}/\"\n",
        "temp_path = path_append + f\"models/{'temp_'}{file_name}/\"\n",
        "log_path = path_append + f\"log/{file_name}/\"\n",
        "\n",
        "if Path(temp_path).exists() is False: \n",
        "    os.mkdir(temp_path)\n",
        "\n",
        "if Path(model_path).exists() is False: \n",
        "    os.mkdir(model_path)\n",
        "\n",
        "if Path(log_path).exists() is False: \n",
        "    os.mkdir(log_path)  \n",
        "\n",
        "args.model_path = model_path\n",
        "args.temp_path = temp_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "args.num_epoch = 10\n",
        "args.lr = 2e-4\n",
        "args.batch_size = 64\n",
        "args.step_size = 10\n",
        "\n",
        "args.num_layer = 3\n",
        "args.hidden_size = 256\n",
        "\n",
        "args.obs_size = 30\n",
        "args.label_size = 1\n",
        "args.explain_size = 1  \n",
        "args.seq_len = 0\n",
        "\n",
        "args.num_checkpoints = 100\n",
        "args.use_one_hot = False\n",
        "\n",
        "args.reasoner_joint_type = \"add\"\n",
        "args.producer_joint_type = \"add\"\n",
        "args.label_type = \"UC\" \n",
        "\n",
        "args.obs_fn = \"none\"\n",
        "args.label_fn = \"none\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_sizes = [0.2, 0.6, 0.8, 0.9]\n",
        "\n",
        "for test_size in test_sizes:\n",
        "\n",
        "    args.num_epoch = int(round(3.2/(1 - test_size)))\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, shuffle= False)\n",
        "\n",
        "    X_train = X_train.iloc[:, :].values \n",
        "    X_test = X_test.iloc[:, :].values \n",
        "    y_train = y_train.iloc[:, -1].values\n",
        "    y_test = y_test.iloc[:, -1].values\n",
        "\n",
        "    trainset = Dataset(X_train, y_train)\n",
        "    testset = Dataset(X_test, y_test)\n",
        "    \n",
        "    args.loss_type = \"L1\"\n",
        "    args.error_type = \"Sub\"\n",
        "    args.loss_reduction = \"all\"\n",
        "    args.error_reduction = \"none\"\n",
        "    log_details = create_log_details(args)\n",
        "    args.log = SummaryWriter(log_dir=create_log_name(log_path, log_details))\n",
        "    set_random_seed(0)\n",
        "\n",
        "    ccnets = CCNets(args, MLP, DeepFM, ResMLP)\n",
        "    ccnets.train(trainset, testset)\n",
        "\n",
        "    args.loss_type = \"MSE\"\n",
        "    args.loss_reduction = \"all\"\n",
        "    log_details = create_log_details(args)\n",
        "    args.log = SummaryWriter(log_dir=create_log_name(log_path, log_details))\n",
        "    set_random_seed(0)\n",
        "    resnets = ResNets(args, MLP, DeepFM)\n",
        "    resnets.train(trainset, testset)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "metadata": {
      "interpreter": {
        "hash": "a7e81af88087f1f4bdc1f0426df14b24fa2673362c5daa7f7f9146748f40b3b1"
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "2415f77ce1baa3f81086790b8c70f527bbeef8a04adfee5bd8dfe28a5524d263"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
